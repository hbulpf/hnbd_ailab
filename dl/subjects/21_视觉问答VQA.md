视觉问答（Visual Question Answering，VQA）专知荟萃
# 入门学习
1. 基于深度学习的VQA（视觉问答）技术  [ https://zhuanlan.zhihu.com/p/22530291 ]
1. 视觉问答全景概述：从数据集到技术方法
1. https://mp.weixin.qq.com/s/dyor9bv2y0VyX7woMDVLkA
1. 论文读书笔记（Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding）  [ http://www.jianshu.com/p/5bf03d1fadfa ]
1. 能看图回答问题的AI离我们还有多远？Facebook向视觉对话进发  [ https://www.leiphone.com/news/201711/4B9cNlCINsVyPdTw.html ]
1. 图像问答Image Question Answering  [ http://www.cnblogs.com/ranjiewen/p/7604468.html ]
1. 实战深度学习之图像问答  [ https://zhuanlan.zhihu.com/p/20899091 ]### 2017 VQA Challenge 第一名技术报告  [ https://zhuanlan.zhihu.com/p/29688475 ]
1. 深度学习为视觉和语言之间搭建了一座桥梁  [ http://www.msra.cn/zh-cn/news/features/vision-and-language-20170713 ]

# 进阶论文
1. Kushal Kafle, and Christopher Kanan. Visual question answering: Datasets, algorithms, and future challenges. Computer Vision and Image Understanding   [ 2017 ].  [ https://arxiv.org/abs/1610.01465 ]
1. Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick, CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning, CVPR 2017.  [ http://vision.stanford.edu/pdf/johnson2017cvpr.pdf ]
1. Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Judy Hoffman, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick, Inferring and Executing Programs for Visual Reasoning, arXiv:1705.03633, 2017.   [ https://arxiv.org/abs/1705.03633 ]
1. Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Kate Saenko, Learning to Reason: End-to-End Module Networks for Visual Question Answering, arXiv:1704.05526, 2017.   [ https://arxiv.org/abs/1704.05526 ]
1. Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap, A simple neural network module for relational reasoning, arXiv:1706.01427, 2017.   [ https://arxiv.org/abs/1706.01427 ]
1. Hedi Ben-younes, Remi Cadene, Matthieu Cord, Nicolas Thome: MUTAN: Multimodal Tucker Fusion for Visual Question Answering   [ https://arxiv.org/pdf/1705.06676.pdf ]   [ https://github.com/Cadene/vqa.pytorch ]
1. Vahid Kazemi, Ali Elqursh, Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering, arXiv:1704.03162, 2016.   [ https://arxiv.org/abs/1704.03162 ]   [ https://github.com/Cyanogenoid/pytorch-vqa ]
1. Kushal Kafle, and Christopher Kanan. An Analysis of Visual Question Answering Algorithms. arXiv:1703.09684, 2017.   [ https://arxiv.org/abs/1703.09684 ]
1. Hyeonseob Nam, Jung-Woo Ha, Jeonghee Kim, Dual Attention Networks for Multimodal Reasoning and Matching, arXiv:1611.00471, 2016.   [ https://arxiv.org/abs/1611.00471 ]
1. Jin-Hwa Kim, Kyoung Woon On, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang, Hadamard Product for Low-rank Bilinear Pooling, arXiv:1610.04325, 2016.   [ https://arxiv.org/abs/1610.04325 ]
1. Akira Fukui, Dong Huk Park, Daylen Yang, Anna Rohrbach, Trevor Darrell, Marcus Rohrbach, Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, arXiv:1606.01847, 2016.   [ https://arxiv.org/abs/1606.01847 ]   [ https://github.com/akirafukui/vqa-mcb ]
1. Kuniaki Saito, Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada, DualNet: Domain-Invariant Network for Visual Question Answering. arXiv:1606.06108v1, 2016.   [ https://arxiv.org/pdf/1606.06108.pdf ]
1. Arijit Ray, Gordon Christie, Mohit Bansal, Dhruv Batra, Devi Parikh, Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions, arXiv:1606.06622, 2016.   [ https://arxiv.org/pdf/1606.06622v1.pdf ]
1. Hyeonwoo Noh, Bohyung Han, Training Recurrent Answering Units with Joint Loss Minimization for VQA, arXiv:1606.03647, 2016.   [ http://arxiv.org/abs/1606.03647v1 ]
1. Jiasen Lu, Jianwei Yang, Dhruv Batra, Devi Parikh, Hierarchical Question-Image Co-Attention for Visual Question Answering, arXiv:1606.00061, 2016.   [ https://arxiv.org/pdf/1606.00061v2.pdf ]   [ https://github.com/jiasenlu/HieCoAttenVQA ]
1. Jin-Hwa Kim, Sang-Woo Lee, Dong-Hyun Kwak, Min-Oh Heo, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang, Multimodal Residual Learning for Visual QA, arXiv:1606.01455, 2016.   [ https://arxiv.org/pdf/1606.01455v1.pdf ]
1. Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, Anthony Dick, FVQA: Fact-based Visual Question Answering, arXiv:1606.05433, 2016.   [ https://arxiv.org/pdf/1606.05433.pdf ]
1. Ilija Ilievski, Shuicheng Yan, Jiashi Feng, A Focused Dynamic Attention Model for Visual Question Answering, arXiv:1604.01485.   [ https://arxiv.org/pdf/1604.01485v1.pdf ]
1. Yuke Zhu, Oliver Groth, Michael Bernstein, Li Fei-Fei, Visual7W: Grounded Question Answering in Images, CVPR 2016.   [ http://arxiv.org/abs/1511.03416 ]
1. Hyeonwoo Noh, Paul Hongsuck Seo, and Bohyung Han, Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction, CVPR, 2016.  [ http://arxiv.org/pdf/1511.05756.pdf ]
1. Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein, Learning to Compose Neural Networks for Question Answering, NAACL 2016.   [ http://arxiv.org/pdf/1601.01705.pdf ]
1. Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein, Deep compositional question answering with neural module networks, CVPR 2016.   [ https://arxiv.org/abs/1511.02799 ]
1. Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola, Stacked Attention Networks for Image Question Answering, CVPR 2016.   [ http://arxiv.org/abs/1511.02274 ]   [ https://github.com/JamesChuanggg/san-torch ]
1. Kevin J. Shih, Saurabh Singh, Derek Hoiem, Where To Look: Focus Regions for Visual Question Answering, CVPR, 2015.   [ http://arxiv.org/pdf/1511.07394v2.pdf ]
1. Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, Ram Nevatia, ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering, arXiv:1511.05960v1, Nov 2015.   [ http://arxiv.org/pdf/1511.05960v1.pdf ]
1. Huijuan Xu, Kate Saenko, Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering, arXiv:1511.05234v1, Nov 2015.   [ http://arxiv.org/abs/1511.05234 ]
1. Kushal Kafle and Christopher Kanan, Answer-Type Prediction for Visual Question Answering, CVPR 2016.   [ http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Kafle_Answer-Type_Prediction_for_CVPR_2016_paper.html ]
1. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, VQA: Visual Question Answering, ICCV, 2015.   [ http://arxiv.org/pdf/1505.00468 ]
1. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, VQA: Visual Question Answering, ICCV, 2015.   [ http://arxiv.org/pdf/1505.00468 ]   [ https://github.com/JamesChuanggg/VQA-tensorflow ]
1. Bolei Zhou, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus, Simple Baseline for Visual Question Answering, arXiv:1512.02167v2, Dec 2015.   [ http://arxiv.org/abs/1512.02167 ]
1. Hauyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, Wei Xu, Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering, NIPS 2015.   [ http://arxiv.org/pdf/1505.05612.pdf ]
1. Mateusz Malinowski, Marcus Rohrbach, Mario Fritz, Ask Your Neurons: A Neural-based Approach to Answering Questions about Images, ICCV 2015.   [ http://arxiv.org/pdf/1505.01121v3.pdf ]
1. Mengye Ren, Ryan Kiros, Richard Zemel, Exploring Models and Data for Image Question Answering, ICML 2015.   [ http://arxiv.org/pdf/1505.02074.pdf ]
1. Mateusz Malinowski, Mario Fritz, Towards a Visual Turing Challe, NIPS Workshop 2015.   [ http://arxiv.org/abs/1410.8027 ]
1. Mateusz Malinowski, Mario Fritz, A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input, NIPS 2014.   [ http://arxiv.org/pdf/1410.0210v4.pdf ]

### Attention-Based
1. Hedi Ben-younes, Remi Cadene, Matthieu Cord, Nicolas Thome: MUTAN: Multimodal Tucker Fusion for Visual Question Answering   [ https://arxiv.org/pdf/1705.06676.pdf ]   [ https://github.com/Cadene/vqa.pytorch ]
1. Jin-Hwa Kim, Kyoung Woon On, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang, Hadamard Product for Low-rank Bilinear Pooling, arXiv:1610.04325, 2016.   [ https://arxiv.org/abs/1610.04325 ]
1. Akira Fukui, Dong Huk Park, Daylen Yang, Anna Rohrbach, Trevor Darrell, Marcus Rohrbach, Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, arXiv:1606.01847, 2016.   [ https://arxiv.org/abs/1606.01847 ]
1. Hyeonwoo Noh, Bohyung Han, Training Recurrent Answering Units with Joint Loss Minimization for VQA, arXiv:1606.03647, 2016.   [ http://arxiv.org/abs/1606.03647v1 ]
1. Jiasen Lu, Jianwei Yang, Dhruv Batra, Devi Parikh, Hierarchical Question-Image Co-Attention for Visual Question Answering, arXiv:1606.00061, 2016.   [ https://arxiv.org/pdf/1606.00061v2.pdf ]
1. Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola, Stacked Attention Networks for Image Question Answering, CVPR 2016.   [ http://arxiv.org/abs/1511.02274 ]
1. Ilija Ilievski, Shuicheng Yan, Jiashi Feng, A Focused Dynamic Attention Model for Visual Question Answering, arXiv:1604.01485.   [ https://arxiv.org/pdf/1604.01485v1.pdf ]
1. Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, Ram Nevatia, ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering, arXiv:1511.05960v1, Nov 2015.   [ http://arxiv.org/pdf/1511.05960v1.pdf ]
1. Huijuan Xu, Kate Saenko, Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering, arXiv:1511.05234v1, Nov 2015.   [ http://arxiv.org/abs/1511.05234 ]

### Knowledge-based
1. Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, Anthony Dick, FVQA: Fact-based Visual Question Answering, arXiv:1606.05433, 2016.   [ https://arxiv.org/pdf/1606.05433.pdf ]
1. Qi Wu, Peng Wang, Chunhua Shen, Anton van den Hengel, Anthony Dick, Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources, CVPR 2016.   [ http://arxiv.org/abs/1511.06973 ]
1. Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, Anthony Dick, Explicit Knowledge-based Reasoning for Visual Question Answering, arXiv:1511.02570v2, Nov 2015.   [ http://arxiv.org/abs/1511.02570 ]
1. Yuke Zhu, Ce Zhang, Christopher Re,́ Li Fei-Fei, Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries, arXiv:1507.05670, Nov 2015.   [ http://arxiv.org/abs/1507.05670 ]

### Memory Network
1. Caiming Xiong, Stephen Merity, Richard Socher, Dynamic Memory Networks for Visual and Textual Question Answering, ICML 2016.   [ http://arxiv.org/abs/1603.01417 ]
1. Aiwen Jiang, Fang Wang, Fatih Porikli, Yi Li, Compositional Memory for Visual Question Answering, arXiv:1511.05676v1, Nov 2015.   [ http://arxiv.org/abs/1511.05676 ]

### Video QA
1. Kuo-Hao Zeng, Tseng-Hung Chen, Ching-Yao Chuang, Yuan-Hong Liao, Juan Carlos Niebles, Min Sun, Leveraging Video Descriptions to Learn Video Question Answering, AAAI 2017.   [ https://arxiv.org/abs/1611.04021 ]
1. Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, Sanja Fidler, MovieQA: Understanding Stories in Movies through Question-Answering, CVPR 2016.   [ http://arxiv.org/abs/1512.02902 ]
1. Linchao Zhu, Zhongwen Xu, Yi Yang, Alexander G. Hauptmann, Uncovering Temporal Context for Video Question and Answering, arXiv:1511.05676v1, Nov 2015.   [ http://arxiv.org/abs/1511.04670 ]

# 综述
1. Qi Wu, Damien Teney, Peng Wang, Chunhua Shen, Anthony Dick, and Anton van den Hengel. Visual question answering: A survey of methods and datasets. Computer Vision and Image Understanding   [ 2017 ].  [ https://arxiv.org/abs/1607.05910 ]
1. Tutorial on Answering Questions about Images with Deep Learning Mateusz Malinowski, Mario Fritz  [ https://arxiv.org/abs/1610.01076 ]
1. Survey of Visual Question Answering: Datasets and Techniques  [ https://arxiv.org/abs/1705.03865 ]
1. Visual Question Answering: Datasets, Algorithms, and Future Challenges  [ https://arxiv.org/abs/1610.01465 ]

# Tutorial
1. CVPR 2017 VQA Challenge Workshop  （有很多PPT）  [ http://www.visualqa.org/workshop.html ]
1. CVPR 2016 VQA Challenge Workshop   [ http://www.visualqa.org/vqa_v1_workshop.html ]
1. Tutorial on Answering Questions about Images with Deep Learning  [ https://arxiv.org/pdf/1610.01076.pdf ]
1. Visual Question Answering Demo in Python Notebook  [ http://iamaaditya.github.io/2016/04/visual_question_answering_demo_notebook ]
1. Tutorial on Question Answering about Images  [ https://www.linkedin.com/pulse/tutorial-question-answering-images-mateusz-malinowski/ ]

# Dataset
1. Visual7W: Grounded Question Answering in Images
1. homepage: http://web.stanford.edu/~yukez/visual7w/
1. github: https://github.com/yukezhu/visual7w-toolkit
1. github: https://github.com/yukezhu/visual7w-qa-models
1. DAQUAR  [ http://www.cs.toronto.edu/~mren/imageqa/results/ ]
1. COCO-QA  [ http://www.cs.toronto.edu/~mren/imageqa/data/cocoqa/ ]
1. The VQA Dataset  [ http://visualqa.org/ ]
1. FM-IQA  [ http://idl.baidu.com/FM-IQA.html ]
1. Visual Genome  [ http://visualgenome.org/ ]

# Code
1. VQA Demo: Visual Question Answering Demo on pretrained model  [ https://github.com/iamaaditya/VQA_Demo ]  [ http://iamaaditya.github.io/research/ ]
1. deep-qa: Implementation of the Convolution Neural Network for factoid QA on the answer sentence selection task  [ https://github.com/aseveryn/deep-qa ]
1. YodaQA: A Question Answering system built on top of the Apache UIMA framework  [ http://ailao.eu/yodaqa/ ]  [ https://github.com/brmson/yodaqa ]
1. insuranceQA-cnn-lstm: tensorflow and theano cnn code for insurance QA  [ https://github.com/white127/insuranceQA-cnn-lstm ]
1. Tensorflow Implementation of Deeper LSTM+ normalized CNN for Visual Question Answering  [ https://github.com/JamesChuanggg/VQA-tensorflow ]
1. Visual Question Answering with Keras  [ https://anantzoid.github.io/VQA-Keras-Visual-Question-Answering/ ]
1. Deep Learning Models for Question Answering with Keras  [ http://sujitpal.blogspot.jp/2016/10/deep-learning-models-for-question.html ]
1. Deep QA: Using deep learning to answer Aristo's science questions  [ https://github.com/allenai/deep_qa ]
1. Visual Question Answering in Pytorch  [ https://github.com/Cadene/vqa.pytorch ]

# 领域专家
1. Qi Wu  [ https://researchers.adelaide.edu.au/profile/qi.wu01 ]
1. Bolei Zhou 周博磊  [ http://people.csail.mit.edu/bzhou/ ]
1. Stanislaw Antol  [ https://computing.ece.vt.edu/~santol/ ]
1. Jin-Hwa Kim  [ https://bi.snu.ac.kr/~jhkim/ ]
1. Vahid Kazemi  [ http://www.csc.kth.se/~vahidk/index.html ]
1. Justin Johnson  [ http://cs.stanford.edu/people/jcjohns/ ]
1. Ilija Ilievski  [ https://ilija139.github.io/ ]

# 参考
1. 视觉问答 . http://www.zhuanzhi.ai/topic/2001033589667352/awesome